{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **kernel** is the central component of Semantic Kernel. At its simplest, the kernel is a Dependency Injection container that manages all of the services and plugins necessary to run your AI application. If you provide all of your services and plugins to the kernel, they will then be seamlessly used by the AI as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our kernel\n",
    "from semantic_kernel import Kernel\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Components of Semantic Kernel\n",
    "- **AI Service Connectors**: These provide a unified interface to access various AI services like text generation, embeddings, and image-to-text, enabling seamless integration with multiple providers.\n",
    "- **Vector Store (Memory) Connectors**: These allow interaction with vector databases for tasks like vector search, which can be exposed as plugins for use in AI workflows.\n",
    "- **Functions and Plugins**: Plugins are containers for functions that can be registered with the kernel, enabling their use in templates or direct invocation by the AI.\n",
    "- **Prompt Templates**: These templates combine user input, context, and instructions for the AI, serving as a starting point for workflows or as callable plugin functions.\n",
    "- **Filters**: These enhance security and control by managing how and when functions run. They include types like Function Invocation Filters, Prompt Render Filters, and Auto Function Invocation Filters, which handle tasks such as validating permissions, modifying prompts, and managing automatic function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now configure our Chat Completion service on the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "# kernel.remove_all_services()\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "service_id = \"default\"\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a Semantic Function\n",
    "\n",
    "Load a Plugin and run a semantic function: A Prompt Plugin is a collection of Semantic Functions, where each function is defined with natural language that can be provided with a text file. Refer to our [glossary](https://github.com/microsoft/semantic-kernel/blob/main/docs/GLOSSARY.md) for an in-depth guide to the terms. For instance, [this](../prompt_template_samples/FunPlugin/Joke/skprompt.txt) is the **Joke function** part of the **FunPlugin plugin**:\n",
    "\n",
    "Let's move on to learning what prompts are and how to write them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "WRITE EXACTLY ONE JOKE or HUMOROUS STORY ABOUT THE TOPIC BELOW.\n",
    "JOKE MUST BE:\n",
    "- G RATED\n",
    "- WORKPLACE/FAMILY SAFE\n",
    "NO SEXISM, RACISM OR OTHER BIAS/BIGOTRY.\n",
    "BE CREATIVE AND FUNNY. I WANT TO LAUGH.\n",
    "+++++\n",
    "{{$input}}\n",
    "+++++\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the special **`{{$input}}`** token, which is a variable that is automatically passed when invoking the function, commonly referred to as a \"function parameter\".\n",
    "\n",
    "We'll explore later how functions can accept multiple variables, as well as invoke other functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same folder you'll notice a second [config.json](../../../prompt_template_samples/FunPlugin/Joke/config.json) file. The file is optional, and is used to set some parameters for large language models like Temperature, TopP, Stop Sequences, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out a joke..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin = kernel.add_plugin(parent_directory=\"../prompt_template_samples/\", plugin_name=\"FunPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "joke_function = plugin[\"Joke\"]\n",
    "\n",
    "joke = await kernel.invoke(\n",
    "    joke_function,\n",
    "    KernelArguments(input=\"time travel to dinosaur age\", style=\"super silly\"),\n",
    ")\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out an excuse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "excuse_function = plugin[\"Excuses\"]\n",
    "\n",
    "excuse = await kernel.invoke(\n",
    "    joke_function,\n",
    "    KernelArguments(input=\"I can't make it to the workshop!\", style=\"super silly\"),\n",
    ")\n",
    "print(excuse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
